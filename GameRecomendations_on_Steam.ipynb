{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Suggestion System\n",
    "\n",
    "In this project, I have implemented a game suggestion system based on Steam data obtained from Kaggle.com. The steps I took to complete this work were as follows:\n",
    "\n",
    "- **Import Libraries:** Imported all the necessary libraries.\n",
    "- **Database Management:** Used `sqlite3` to manage the data with SQL for faster performance.\n",
    "- **Data Transformation:** Transformed the data to make it optimal for the machine learning algorithm.\n",
    "- **Nearest Neighbors Algorithm:** Utilized the Nearest Neighbors algorithm to find similarities in the data.\n",
    "- **Recommendations:** Generated and presented some recommendations.\n",
    "\n",
    "I began by importing all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import re \n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enhance query performance, two indexes have been created.\n",
    "These indexes facilitate quicker retrieval of data, improving the overall efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('GameRecomendations_on_Steam.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('CREATE INDEX IF NOT EXISTS idx_Recommendations_user_id ON Recommendations (user_id);')\n",
    "cursor.execute('CREATE INDEX IF NOT EXISTS idx_Recommendations_app_id ON Recommendations (app_id);')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I used SQL queries to select, join, and filter the data. In this step, I obtained:\n",
    "\n",
    "- The games that the user recommends. I will use this information to recommend more games to the user.\n",
    "- All Steam games until 2019. This data will be used to train the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others interesting user_id: 34580 504588\n",
    "with sqlite3.connect(\"GameRecomendations_on_Steam.db\") as conn:\n",
    "    query = '''\n",
    "        SELECT s.name as title\n",
    "        FROM Recommendations r\n",
    "        INNER JOIN Steam s \n",
    "        ON r.app_id = s.appid\n",
    "        WHERE r.user_id = 45805 and is_recommended = \"true\";\n",
    "    '''\n",
    "    user = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    query = '''\n",
    "        SELECT s.name as title, s.genres, s.price, s.steamspy_tags\n",
    "        FROM Games AS g \n",
    "        INNER JOIN Steam s\n",
    "        ON g.app_id = s.appid\n",
    "        ORDER BY app_id\n",
    "    ''' \n",
    "    games_df = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns 'categories', 'genres', and 'steamspy_tags' contain multiple attributes separated by semicolons. To address this, I split these attributes into different columns. Subsequently, I use One Hot Encoding (OHE) to convert the categorical data into a format suitable for machine learning algorithms. Afterward, I remove the duplicated columns generated by OHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHERemoveDuplicated(df, column):\n",
    "    column_split = df[column].str.split(';', expand=True)\n",
    "    df_drop = df.drop([column], axis =1 )\n",
    "\n",
    "    column_encoded = pd.get_dummies(column_split, prefix=column)\n",
    "    column_encoded = column_encoded.astype(int)\n",
    "\n",
    "    combinated_columns = column_encoded.copy()\n",
    "    l = []\n",
    "    for row in column_encoded.loc[:, column_encoded.columns.duplicated()].columns:\n",
    "        if row in l:\n",
    "            continue\n",
    "        combinated_columns[row] = combinated_columns[row].sum(axis=1)\n",
    "        column_encoded = column_encoded.drop(row, axis=1)\n",
    "        l.append(row)\n",
    "\n",
    "    df_concat = pd.concat([df_drop, combinated_columns, column_encoded], axis=1)\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I apply the funtion on the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = OHERemoveDuplicated(games_df, \"genres\" )\n",
    "X = OHERemoveDuplicated(X, \"steamspy_tags\" )\n",
    "c = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, I define custom transformers:\n",
    "\n",
    "- **TextPreprocessor:** This transformer removes numbers and punctuation marks from text, preparing the data for the next transformer.\n",
    "- **TfidfSumVectorizer:** This transformer is used to process categorical data, specifically titles and genres. It assigns a score to each word based on its frequency in the column, then sums the total score for each row within its column.\n",
    "- **convert_to_dataframe:** This transformer simply converts an array to a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        out = X.apply(lambda x: self._preprocess_text(x))\n",
    "        return pd.DataFrame(out)\n",
    "    \n",
    "    def _preprocess_text(self, text):\n",
    "        \"\"\" \n",
    "        Removes numbers and punvtuation marks\n",
    "        \"\"\"\n",
    "        if text is None:\n",
    "            return \"No name register\"\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]+', ' ', text)\n",
    "        text = text.lower()\n",
    "        return text if text.strip() else \"just number\"\n",
    "    \n",
    "class TfidfSumVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Use TfidfVectorizer to assigs score to each word and the sums \n",
    "        the score of the whole sentence\n",
    "        \"\"\"\n",
    "        tfidf_matrix = self.vectorizer.transform(X)\n",
    "        row_sum = np.sum(csr_matrix(tfidf_matrix).todense(), axis=1)\n",
    "        return row_sum\n",
    "    \n",
    "\n",
    "def convert_to_dataframe(X):\n",
    "    \"\"\"\n",
    "    to convert to pd Data Frame\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame(X, columns=c)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I define the transformers and specify the columns to which they are applied. Then, I create a pipeline where the entire workflow is defined. Finally, I use MinMaxScaler to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('title', TextPreprocessor(), 'title'),\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf_title', TfidfSumVectorizer(), 'title'),\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('text', text_transformer),\n",
    "    ('conversion', FunctionTransformer(func=convert_to_dataframe, validate=False)),\n",
    "    ('tfidf', column_transformer)\n",
    "])\n",
    "\n",
    "X_2 = pipeline.fit_transform(X)\n",
    "X_2 = pd.DataFrame(X_2, columns=X.columns)\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_2 = min_max_scaler.fit_transform(X_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, i use nearest neighbors and fit the algoritm to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = NearestNeighbors(metric='minkowski', algorithm='brute')\n",
    "model_knn.fit(X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, i use the user recommended games to recommend him 3 games for each game he recommends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: Papers, Please\n",
      "Genres: Adventure;Indie\n",
      "Recommended games: ['Asemblance: Oversight', 'Neptune Flux', 'Castle Agony']\n",
      "\n",
      "Game: Microsoft Flight Simulator X: Steam Edition\n",
      "Genres: Simulation\n",
      "Recommended games: ['X-Plane 11', 'Take Off - The Flight Simulator', 'Wings Over Europe']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for game in user[\"title\"]:\n",
    "    indice_fila = games_df.loc[games_df['title'] == game].index[0]\n",
    "    genres = games_df.loc[games_df['title'] == game][\"genres\"]\n",
    "    datos_game = X_2[indice_fila]\n",
    "    datos_game = pd.DataFrame(datos_game).T\n",
    "    \n",
    "    print(f'Game: {game}')\n",
    "    print(f'Genres: {genres.values[0]}')\n",
    "    \n",
    "    distances, indices = model_knn.kneighbors(datos_game, n_neighbors=4)\n",
    "    recommended_users = [games_df.iloc[i]['title'] for i in indices.flatten() if games_df.iloc[i]['title'] != game]\n",
    "    print(f'Recommended games: {recommended_users}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- The algorithm successfully recommends games that align with user preferences.\n",
    "- The games recommened has a lot in common with the game recommended by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
